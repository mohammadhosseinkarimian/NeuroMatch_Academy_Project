{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c3e89aca-6c52-4b20-b1a3-9279ef0fd99b",
      "metadata": {
        "id": "c3e89aca-6c52-4b20-b1a3-9279ef0fd99b"
      },
      "source": [
        "# Deep Q-Network (DQN) on LunarLander-v2\n",
        "\n",
        "> In this post, We will take a hands-on-lab of Simple Deep Q-Network (DQN) on openAI LunarLander-v2 environment. This is the coding exercise from udacity Deep Reinforcement Learning Nanodegree.\n",
        "\n",
        "- toc: true \n",
        "- badges: true\n",
        "- comments: true\n",
        "- author: Chanseok Kang\n",
        "- categories: [Python, Reinforcement_Learning, PyTorch, Udacity]\n",
        "- image: images/LunarLander-v2.gif"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd834f1b-51c4-4910-a4d6-3b212e1a2a5a",
      "metadata": {
        "id": "fd834f1b-51c4-4910-a4d6-3b212e1a2a5a"
      },
      "source": [
        "## Deep Q-Network (DQN)\n",
        "---\n",
        "In this notebook, you will implement a DQN agent with OpenAI Gym's LunarLander-v2 environment.\n",
        "\n",
        "### Import the Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "AYDZ7aX1N4p6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYDZ7aX1N4p6",
        "outputId": "0dfde9df-c478-46cf-c0cd-c8465e0e6ab7"
      },
      "outputs": [],
      "source": [
        "# !pip install gym[box2d] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "22518486-3c2f-47fe-92b3-1502875eacfe",
      "metadata": {
        "id": "22518486-3c2f-47fe-92b3-1502875eacfe"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import base64, io\n",
        "\n",
        "import numpy as np\n",
        "from collections import deque, namedtuple\n",
        "\n",
        "# For visualization\n",
        "from gym.wrappers.monitoring import video_recorder\n",
        "from IPython.display import HTML\n",
        "from IPython import display \n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f75f934c-6921-43aa-8389-6df4b993eca4",
      "metadata": {
        "id": "f75f934c-6921-43aa-8389-6df4b993eca4"
      },
      "source": [
        "### Instantiate the Environment and Agent\n",
        "\n",
        "Initialize the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "594828b6-da33-481d-ab42-041e8c17ffea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "594828b6-da33-481d-ab42-041e8c17ffea",
        "outputId": "f9d61d7e-5eb6-43e0-92ae-95726f6a0a43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State shape:  (8,)\n",
            "Number of actions:  4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\RL\\gym\\venv\\lib\\site-packages\\gym\\core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "import lunar_lander\n",
        "\n",
        "# env = gym.make('LunarLander-v2')\n",
        "env = lunar_lander.LunarLander()\n",
        "env.seed(0)\n",
        "print('State shape: ', env.observation_space.shape)\n",
        "print('Number of actions: ', env.action_space.n)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03735bdc-c07e-4c87-b208-cce894bb8e43",
      "metadata": {
        "id": "03735bdc-c07e-4c87-b208-cce894bb8e43"
      },
      "source": [
        "### Define Neural Network Architecture.\n",
        "\n",
        "Since `LunarLander-v2` environment is sort of simple envs, we don't need complicated architecture. We just need non-linear function approximator that maps from state to action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "ae834607-433e-4ed5-8b23-8de7b53230a8",
      "metadata": {
        "id": "ae834607-433e-4ed5-8b23-8de7b53230a8"
      },
      "outputs": [],
      "source": [
        "class QNetwork(nn.Module):\n",
        "    \"\"\"Actor (Policy) Model.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, seed):\n",
        "        \"\"\"Initialize parameters and build model.\n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): Dimension of each state\n",
        "            action_size (int): Dimension of each action\n",
        "            seed (int): Random seed\n",
        "        \"\"\"\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.fc1 = nn.Linear(state_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, action_size)\n",
        "        \n",
        "    def forward(self, state):\n",
        "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
        "        x = self.fc1(state)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        return self.fc3(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0873298-cab0-4dcb-9c84-4782dc914dd7",
      "metadata": {
        "id": "b0873298-cab0-4dcb-9c84-4782dc914dd7"
      },
      "source": [
        "### Define some hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "7010c525-29d8-445c-8769-6cfb7d00948b",
      "metadata": {
        "id": "7010c525-29d8-445c-8769-6cfb7d00948b"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
        "BATCH_SIZE = 64         # minibatch size\n",
        "GAMMA = 0.99            # discount factor\n",
        "TAU = 1e-3              # for soft update of target parameters\n",
        "LR = 5e-4               # learning rate \n",
        "UPDATE_EVERY = 4        # how often to update the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "334bb7d8-7d62-4cfb-96f7-f8809ba8e089",
      "metadata": {
        "id": "334bb7d8-7d62-4cfb-96f7-f8809ba8e089"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d861efe-200c-4690-9698-722abbf0b77c",
      "metadata": {
        "id": "1d861efe-200c-4690-9698-722abbf0b77c"
      },
      "source": [
        "### Define Agent "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "0530f456-2bfd-4061-ad62-f14846a9a284",
      "metadata": {
        "id": "0530f456-2bfd-4061-ad62-f14846a9a284"
      },
      "outputs": [],
      "source": [
        "class Agent():\n",
        "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, seed):\n",
        "        \"\"\"Initialize an Agent object.\n",
        "        \n",
        "        Params\n",
        "        ======\n",
        "            state_size (int): dimension of each state\n",
        "            action_size (int): dimension of each action\n",
        "            seed (int): random seed\n",
        "        \"\"\"\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.seed = random.seed(seed)\n",
        "\n",
        "        # Q-Network\n",
        "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
        "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
        "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
        "\n",
        "        # Replay memory\n",
        "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
        "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
        "        self.t_step = 0\n",
        "    \n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        # Save experience in replay memory\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "        \n",
        "        # Learn every UPDATE_EVERY time steps.\n",
        "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
        "        if self.t_step == 0:\n",
        "            # If enough samples are available in memory, get random subset and learn\n",
        "            if len(self.memory) > BATCH_SIZE:\n",
        "                experiences = self.memory.sample()\n",
        "                self.learn(experiences, GAMMA)\n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "        \"\"\"Returns actions for given state as per current policy.\n",
        "        \n",
        "        Params\n",
        "        ======\n",
        "            state (array_like): current state\n",
        "            eps (float): epsilon, for epsilon-greedy action selection\n",
        "        \"\"\"\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        self.qnetwork_local.eval()\n",
        "        with torch.no_grad():\n",
        "            action_values = self.qnetwork_local(state)\n",
        "        self.qnetwork_local.train()\n",
        "\n",
        "        # Epsilon-greedy action selection\n",
        "        if random.random() > eps:\n",
        "            return np.argmax(action_values.cpu().data.numpy())\n",
        "        else:\n",
        "            return random.choice(np.arange(self.action_size))\n",
        "\n",
        "    def learn(self, experiences, gamma):\n",
        "        \"\"\"Update value parameters using given batch of experience tuples.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples \n",
        "            gamma (float): discount factor\n",
        "        \"\"\"\n",
        "        # Obtain random minibatch of tuples from D\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        ## Compute and minimize the loss\n",
        "        ### Extract next maximum estimated value from target network\n",
        "        q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "        ### Calculate target value from bellman equation\n",
        "        q_targets = rewards + gamma * q_targets_next * (1 - dones)\n",
        "        ### Calculate expected value from local network\n",
        "        q_expected = self.qnetwork_local(states).gather(1, actions)\n",
        "        \n",
        "        ### Loss calculation (we used Mean squared error)\n",
        "        loss = F.mse_loss(q_expected, q_targets)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # ------------------- update target network ------------------- #\n",
        "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
        "\n",
        "    def soft_update(self, local_model, target_model, tau):\n",
        "        \"\"\"Soft update model parameters.\n",
        "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            local_model (PyTorch model): weights will be copied from\n",
        "            target_model (PyTorch model): weights will be copied to\n",
        "            tau (float): interpolation parameter \n",
        "        \"\"\"\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eb5db66-ecb3-4bf4-aee1-3e18003c17b0",
      "metadata": {
        "id": "4eb5db66-ecb3-4bf4-aee1-3e18003c17b0"
      },
      "source": [
        "### Define Replay Buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "f74bb08e-0b95-42db-9fc8-d609514d55af",
      "metadata": {
        "id": "f74bb08e-0b95-42db-9fc8-d609514d55af"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
        "\n",
        "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
        "        \"\"\"Initialize a ReplayBuffer object.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            action_size (int): dimension of each action\n",
        "            buffer_size (int): maximum size of buffer\n",
        "            batch_size (int): size of each training batch\n",
        "            seed (int): random seed\n",
        "        \"\"\"\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=buffer_size)  \n",
        "        self.batch_size = batch_size\n",
        "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "        self.seed = random.seed(seed)\n",
        "    \n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Add a new experience to memory.\"\"\"\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        self.memory.append(e)\n",
        "    \n",
        "    def sample(self):\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "\n",
        "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
        "  \n",
        "        return (states, actions, rewards, next_states, dones)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bd61b8d-b63e-444f-9cb7-6295df46995d",
      "metadata": {
        "id": "6bd61b8d-b63e-444f-9cb7-6295df46995d"
      },
      "source": [
        "### Training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "c907ab57-ed48-4824-b27c-8c7d707d6919",
      "metadata": {
        "id": "c907ab57-ed48-4824-b27c-8c7d707d6919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 100\tAverage Score: -162.03\n",
            "Episode 200\tAverage Score: -99.571\n",
            "Episode 300\tAverage Score: -122.28\n",
            "Episode 400\tAverage Score: -65.850\n",
            "Episode 500\tAverage Score: -51.16\n",
            "Episode 600\tAverage Score: 46.168\n",
            "Episode 700\tAverage Score: 70.18\n",
            "Episode 800\tAverage Score: 81.71\n",
            "Episode 900\tAverage Score: 129.63\n",
            "Episode 1000\tAverage Score: 89.57\n",
            "Episode 1100\tAverage Score: 120.66\n",
            "Episode 1200\tAverage Score: 111.37\n",
            "Episode 1300\tAverage Score: 136.65\n",
            "Episode 1376\tAverage Score: 181.31\n",
            "Environment solved in 1276 episodes!\tAverage Score: 181.31\n"
          ]
        }
      ],
      "source": [
        "def dqn(n_episodes=4000, max_t=800, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
        "    \"\"\"Deep Q-Learning.\n",
        "    \n",
        "    Params\n",
        "    ======\n",
        "        n_episodes (int): maximum number of training episodes\n",
        "        max_t (int): maximum number of timesteps per episode\n",
        "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
        "        eps_end (float): minimum value of epsilon\n",
        "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
        "    \"\"\"\n",
        "    \n",
        "    scores = []                        # list containing scores from each episode\n",
        "    scores_window = deque(maxlen=100)  # last 100 scores\n",
        "    eps = eps_start                    # initialize epsilon\n",
        "    for i_episode in range(1, n_episodes+1):\n",
        "        if i_episode > 3700:\n",
        "            eps_end=0.00001\n",
        "            eps_decay = 0.1\n",
        "        state = env.reset()\n",
        "        score = 0\n",
        "        for t in range(max_t):\n",
        "            action = agent.act(state, eps)\n",
        "            next_state, reward, done, _, _ = env.step(action)\n",
        "            agent.step(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            score += reward\n",
        "            if done:\n",
        "                break \n",
        "        scores_window.append(score)       # save most recent score\n",
        "        scores.append(score)              # save most recent score\n",
        "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
        "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
        "        if i_episode % 100 == 0:\n",
        "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
        "        if np.mean(scores_window)>=180.0:\n",
        "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
        "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
        "            break\n",
        "    return scores\n",
        "\n",
        "agent = Agent(state_size=8, action_size=4, seed=0)\n",
        "scores = dqn()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ba6726a-977a-4345-8897-021302bfc262",
      "metadata": {
        "id": "1ba6726a-977a-4345-8897-021302bfc262"
      },
      "source": [
        "### Plot the learning progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "d2d491c9-a5dc-4c32-a95d-796f85c60c83",
      "metadata": {
        "id": "d2d491c9-a5dc-4c32-a95d-796f85c60c83"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot the scores\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(len(scores)), scores)\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Episode #')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebb450a9-c530-4f10-b629-53a2d69860c2",
      "metadata": {
        "id": "ebb450a9-c530-4f10-b629-53a2d69860c2"
      },
      "source": [
        "### Animate it with Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9806a31-f777-468e-8987-0139708ef532",
      "metadata": {
        "id": "c9806a31-f777-468e-8987-0139708ef532"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "049323be",
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_video(env_name):\n",
        "    mp4list = glob.glob('video/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = 'video/{}.mp4'.format(env_name)\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "    else:\n",
        "        print(\"Could not find video\")\n",
        "        \n",
        "def show_video_of_model(agent, env_name):\n",
        "    env = lunar_lander.LunarLander()\n",
        "    vid = video_recorder.VideoRecorder(env, path=\"video/{}.mp4\".format(env_name))\n",
        "    agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
        "    for _ in range(1):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        i =0\n",
        "        while not done:\n",
        "            frame = env.render(mode='rgb_array')\n",
        "            plt.imshow(frame)\n",
        "            vid.capture_frame()\n",
        "            \n",
        "            action = agent.act(state)\n",
        "\n",
        "            state, reward, done, _, _ = env.step(action)        \n",
        "            i = i+1\n",
        "            if i%100 ==0:\n",
        "                print('step', i)\n",
        "    env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "59e53f73",
      "metadata": {},
      "outputs": [],
      "source": [
        "from gym.utils.step_api_compatibility import step_api_compatibility\n",
        "\n",
        "\n",
        "def demo_heuristic_lander(env, seed=None, render=False):\n",
        "\n",
        "    total_reward = 0\n",
        "    steps = 0\n",
        "    s = env.reset(seed=seed)\n",
        "    while True:\n",
        "        # a = heuristic(env, s)\n",
        "        a = agent.act(s)\n",
        "        s, r, terminated, truncated, info = step_api_compatibility(env.step(a), True)\n",
        "        total_reward += r\n",
        "\n",
        "        if render:\n",
        "            still_open = env.render()\n",
        "            if still_open is False:\n",
        "                break\n",
        "\n",
        "        if steps % 20 == 0 or terminated or truncated:\n",
        "            print(\"observations:\", \" \".join([f\"{x:+0.2f}\" for x in s]))\n",
        "            print(f\"step {steps} total_reward {total_reward:+0.2f}\")\n",
        "        steps += 1\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "    if render:\n",
        "        env.close()\n",
        "    return total_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "748b22b3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "observations: -0.00 +1.42 -0.17 +0.16 +0.00 +0.04 +0.00 +0.00\n",
            "step 0 total_reward +1.32\n",
            "observations: -0.04 +1.36 -0.17 -0.38 +0.04 +0.04 +0.00 +0.00\n",
            "step 20 total_reward -15.26\n",
            "observations: -0.07 +1.22 -0.18 -0.18 +0.06 +0.02 +0.00 +0.00\n",
            "step 40 total_reward +7.00\n",
            "observations: -0.12 +1.16 -0.30 -0.09 +0.06 -0.03 +0.00 +0.00\n",
            "step 60 total_reward +3.95\n",
            "observations: -0.18 +1.11 -0.32 -0.10 +0.04 -0.01 +0.00 +0.00\n",
            "step 80 total_reward +3.95\n",
            "observations: -0.25 +1.05 -0.35 -0.09 +0.02 -0.01 +0.00 +0.00\n",
            "step 100 total_reward +4.15\n",
            "observations: -0.32 +1.01 -0.33 -0.08 -0.03 -0.09 +0.00 +0.00\n",
            "step 120 total_reward +4.59\n",
            "observations: -0.37 +0.97 -0.21 -0.04 -0.07 -0.04 +0.00 +0.00\n",
            "step 140 total_reward +11.03\n",
            "observations: -0.42 +0.95 -0.23 -0.06 -0.08 -0.02 +0.00 +0.00\n",
            "step 160 total_reward +4.03\n",
            "observations: -0.46 +0.93 -0.13 -0.04 -0.07 +0.07 +0.00 +0.00\n",
            "step 180 total_reward +11.52\n",
            "observations: -0.48 +0.92 -0.12 -0.01 -0.06 +0.01 +0.00 +0.00\n",
            "step 200 total_reward +9.57\n",
            "observations: -0.50 +0.93 -0.07 +0.01 -0.07 -0.02 +0.00 +0.00\n",
            "step 220 total_reward +9.44\n",
            "observations: -0.51 +0.93 -0.07 -0.01 -0.07 +0.01 +0.00 +0.00\n",
            "step 240 total_reward +4.79\n",
            "observations: -0.52 +0.94 -0.01 +0.03 -0.08 +0.00 +0.00 +0.00\n",
            "step 260 total_reward +1.92\n",
            "observations: -0.52 +0.95 +0.06 +0.01 -0.10 +0.01 +0.00 +0.00\n",
            "step 280 total_reward -6.46\n",
            "observations: -0.50 +0.95 +0.13 +0.01 -0.11 -0.01 +0.00 +0.00\n",
            "step 300 total_reward -19.38\n",
            "observations: -0.47 +0.96 +0.19 +0.00 -0.11 +0.01 +0.00 +0.00\n",
            "step 320 total_reward -27.31\n",
            "observations: -0.42 +0.96 +0.23 -0.03 -0.11 +0.04 +0.00 +0.00\n",
            "step 340 total_reward -33.91\n",
            "observations: -0.38 +0.93 +0.21 -0.12 -0.09 +0.03 +0.00 +0.00\n",
            "step 360 total_reward -31.26\n",
            "observations: -0.32 +0.88 +0.34 -0.10 -0.07 -0.01 +0.00 +0.00\n",
            "step 380 total_reward -37.59\n",
            "observations: -0.24 +0.85 +0.42 -0.04 -0.04 +0.00 +0.00 +0.00\n",
            "step 400 total_reward -39.86\n",
            "observations: -0.15 +0.80 +0.48 -0.14 -0.01 +0.04 +0.00 +0.00\n",
            "step 420 total_reward -41.36\n",
            "observations: -0.06 +0.74 +0.45 -0.19 +0.02 +0.02 +0.00 +0.00\n",
            "step 440 total_reward -36.33\n",
            "observations: +0.03 +0.53 +0.45 -0.72 +0.07 +0.03 +0.00 +0.00\n",
            "step 460 total_reward -66.03\n",
            "observations: +0.11 +0.27 +0.29 -0.36 +0.14 +0.07 +0.00 +0.00\n",
            "step 480 total_reward -60.92\n",
            "observations: +0.15 +0.19 +0.11 -0.06 +0.18 +0.05 +0.00 +0.00\n",
            "step 500 total_reward -32.03\n",
            "observations: +0.16 +0.15 +0.04 -0.13 +0.12 -0.11 +0.00 +0.00\n",
            "step 520 total_reward -28.29\n",
            "observations: +0.16 +0.09 -0.07 -0.10 +0.04 -0.04 +0.00 +0.00\n",
            "step 540 total_reward -18.88\n",
            "observations: +0.14 +0.05 -0.12 -0.10 +0.04 +0.03 +0.00 +0.00\n",
            "step 560 total_reward -22.04\n",
            "observations: +0.11 -0.00 -0.16 -0.08 -0.01 -0.28 +1.00 +1.00\n",
            "step 580 total_reward -1.74\n",
            "observations: +0.11 -0.00 -0.00 +0.00 +0.00 +0.00 +0.00 +1.00\n",
            "step 600 total_reward +6.95\n",
            "observations: +0.11 -0.00 +0.00 +0.00 +0.00 +0.00 +0.00 +1.00\n",
            "step 613 total_reward +106.95\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "106.94739089771902"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_heuristic_lander(lunar_lander.LunarLander(), render=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "id": "4beb1d45-ab9a-4fd7-a769-017bbf1672e1",
      "metadata": {
        "id": "4beb1d45-ab9a-4fd7-a769-017bbf1672e1"
      },
      "outputs": [],
      "source": [
        "# agent = Agent(state_size=8, action_size=4, seed=0)\n",
        "# show_video_of_model(agent, 'LunarLander-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "id": "f54ee0a0-265b-4161-bbb6-25e28543aa2e",
      "metadata": {
        "id": "f54ee0a0-265b-4161-bbb6-25e28543aa2e"
      },
      "outputs": [],
      "source": [
        "# show_video('LunarLander-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06fd3c7c",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "2021-05-07-DQN-LunarLander.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "753877470853750a61c6feb6c4f568ced80a6a2118b2d2e51025618879d185a4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
